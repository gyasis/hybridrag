# =============================================================================
# HybridRAG Environment Configuration
# =============================================================================
# Copy this file to .env and configure your settings.
#
# IMPORTANT: Never commit .env files with real credentials to version control!
# =============================================================================

# -----------------------------------------------------------------------------
# API Keys (choose one provider)
# -----------------------------------------------------------------------------

# OpenAI (direct)
OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_API_BASE=https://api.openai.com/v1  # Optional: custom endpoint

# Azure OpenAI (use azure/ prefix on model names)
# AZURE_API_KEY=your_azure_key
# AZURE_API_BASE=https://your-resource.openai.azure.com
# AZURE_API_VERSION=2025-01-01-preview

# Anthropic (for PromptChain features)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# -----------------------------------------------------------------------------
# Model Configuration (LiteLLM format)
# -----------------------------------------------------------------------------
# Model prefix determines routing:
#   - openai/    = OpenAI API (e.g., openai/gpt-4o-mini)
#   - azure/     = Azure OpenAI (e.g., azure/gpt-5.1)
#   - ollama/    = Local Ollama (e.g., ollama/llama2)
#
# IMPORTANT: When using azure/, you must also set AZURE_API_KEY and AZURE_API_BASE

LIGHTRAG_MODEL=azure/gpt-5.1
AGENTIC_MODEL=azure/gpt-5.1
LIGHTRAG_EMBED_MODEL=azure/text-embedding-3-small

# -----------------------------------------------------------------------------
# EMBEDDING DIMENSION (CRITICAL!)
# -----------------------------------------------------------------------------
# Must match your embedding model's output dimension.
# Wrong value = "No query context could be built" errors.
#
# Common values:
#   - Azure text-embedding-3-small:  768
#   - OpenAI text-embedding-3-small: 1536
#   - OpenAI text-embedding-3-large: 3072
#   - text-embedding-ada-002:        1536

EMBEDDING_DIM=768

# Legacy alias (for backward compatibility)
# LIGHTRAG_EMBEDDING_DIM=768

# -----------------------------------------------------------------------------
# Storage Backend
# -----------------------------------------------------------------------------
# Options: json (default, file-based) or postgres (production)

BACKEND_TYPE=json

# For PostgreSQL backend:
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5433
# POSTGRES_USER=hybridrag
# POSTGRES_PASSWORD=your_secure_password_here
# POSTGRES_DB=hybridrag

# -----------------------------------------------------------------------------
# MCP Server Configuration
# -----------------------------------------------------------------------------
# Used when running HybridRAG as an MCP server for Claude Code

# Database to query (matches registry name or creates dynamically)
HYBRIDRAG_DATABASE_NAME=specstory

# Alternative: explicit database path (overrides DATABASE_NAME)
# HYBRIDRAG_DATABASE=/path/to/lightrag_db

# Logging level for MCP server
HYBRIDRAG_LOG_LEVEL=INFO

# CRITICAL: Never set litellm verbose in production!
# It corrupts MCP stdio protocol. Keep this False.
# (Set in server.py, not here, but documenting for awareness)

# -----------------------------------------------------------------------------
# System Directories
# -----------------------------------------------------------------------------

HYBRIDRAG_DATA_DIR=./data
HYBRIDRAG_LIGHTRAG_DIR=./lightrag_db
HYBRIDRAG_QUEUE_DIR=./ingestion_queue

# Registry configuration (advanced)
# HYBRIDRAG_CONFIG=~/.hybridrag/registry.yaml

# -----------------------------------------------------------------------------
# Performance Tuning
# -----------------------------------------------------------------------------

HYBRIDRAG_MAX_CONCURRENT_INGESTIONS=3
HYBRIDRAG_BATCH_SIZE=10
HYBRIDRAG_POLL_INTERVAL=5.0
HYBRIDRAG_MAX_FILE_SIZE_MB=50.0

# -----------------------------------------------------------------------------
# Search Configuration
# -----------------------------------------------------------------------------

# Default search mode: local, global, hybrid, naive
HYBRIDRAG_DEFAULT_MODE=hybrid

# Number of results to return
HYBRIDRAG_DEFAULT_TOP_K=10

# Enable agentic multi-step reasoning
HYBRIDRAG_ENABLE_AGENTIC=true

# -----------------------------------------------------------------------------
# Database-Specific Environment Variables (Alternative to Registry)
# -----------------------------------------------------------------------------
# Per-database configuration using HYBRIDRAG_{DB_NAME}_ prefix:
#
# HYBRIDRAG_SPECSTORY_SOURCE_FOLDER=/path/to/source
# HYBRIDRAG_SPECSTORY_DATABASE_PATH=/path/to/lightrag_db
# HYBRIDRAG_SPECSTORY_MODEL=azure/gpt-5.1
# HYBRIDRAG_SPECSTORY_AUTO_WATCH=true
# HYBRIDRAG_SPECSTORY_WATCH_INTERVAL=300

# -----------------------------------------------------------------------------
# Docker Configuration (used by docker-compose.postgres.yaml)
# -----------------------------------------------------------------------------

# POSTGRES_PASSWORD=hybridrag_secure_2026
# POSTGRES_PORT=5433
# POSTGRES_DATA_DIR=./data/postgres
