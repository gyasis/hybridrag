# LightRAG Ingestion Commands

## Manual Ingestion Command

To run the DeepLake to LightRAG conversion/ingestion process manually:

```bash
uv run python deeplake_to_lightrag.py
```

## Prerequisites

1. **Environment Setup** (if not already done):
```bash
# Install UV dependencies
uv sync

# Verify environment variables in .env file
cat .env
# Should contain:
# OPENAI_API_KEY=your_openai_api_key_here
```

2. **Database Access**:
   - DeepLake source: `/media/gyasis/Drive 2/Deeplake_Storage/athena_descriptions_v4`
   - Target directory: `./athena_lightrag_db` (created automatically)

## What the Ingestion Process Does

### Phase 1: Initialization âš™ï¸
- Sets up LightRAG storages and pipeline
- Validates OpenAI API key
- Initializes knowledge graph database

### Phase 2: Extraction ğŸ”
- Processes 15,149+ medical table descriptions from DeepLake
- Shows real-time progress with success/error counts
- Formats JSONL records into structured documents
- Validates essential fields (TABLE NAME, SCHEMANAME)

### Phase 3: Ingestion ğŸ“š
- Loads documents into LightRAG knowledge graph
- Batch processing with rate limiting
- Progress tracking with ETA calculation
- Individual retry for failed batches

### Phase 4: Validation ğŸ”
- Tests database responsiveness
- Saves pipeline artifacts and metadata
- Provides next steps for querying

## Expected Output

```
ğŸš€ DEEPLAKE TO LIGHTRAG INGESTION PIPELINE
======================================================================
ğŸ“… Started at: 2024-12-XX XX:XX:XX
ğŸ“‚ Source: /media/gyasis/Drive 2/Deeplake_Storage/athena_descriptions_v4
ğŸ“ Target: ./athena_lightrag_db
ğŸ¤– Model: gpt-4o-mini (text-embedding-ada-002)
======================================================================

âš™ï¸ INITIALIZATION PHASE: Setting up LightRAG storages
âœ… Initialization completed in X.XX seconds

ğŸ” EXTRACTION PHASE: Processing X,XXX records from DeepLake
======================================================================
Extracting documents: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15149/15149 [XX:XX<00:00, XX.X docs/s, Success=15,XXX, Errors=X, Rate=XX.X%]

âœ… EXTRACTION COMPLETE:
   â€¢ Successfully processed: XX,XXX documents
   â€¢ Errors encountered: XXX records
   â€¢ Success rate: XX.X%
   â€¢ Total extracted: XX,XXX documents ready for ingestion

ğŸ“š INGESTION PHASE: Loading XX,XXX documents into LightRAG
======================================================================
ğŸ“Š Configuration:
   â€¢ Batch size: 8 documents
   â€¢ Expected batches: X,XXX
   â€¢ Rate limiting: 1 second between batches

Ingesting to LightRAG: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15149/15149 [XX:XX<00:00, XX.X docs/s, Ingested=XX,XXX, Failed=XX, Rate=X.X/s, ETA=XX:XX:XX]

âœ… INGESTION COMPLETE:
   â€¢ Successfully ingested: XX,XXX documents
   â€¢ Failed documents: XXX
   â€¢ Success rate: XX.X%
   â€¢ Total time: X:XX:XX
   â€¢ Average rate: XX.X docs/second

ğŸ” VALIDATION PHASE: Verifying LightRAG database
âœ… Database validation successful - LightRAG is responsive
ğŸ“ Artifacts saved to: ./athena_lightrag_db/pipeline_artifacts

ğŸ‰ PIPELINE COMPLETED SUCCESSFULLY!
======================================================================
ğŸ“Š SUMMARY STATISTICS:
   â€¢ Total documents processed: XX,XXX
   â€¢ Total pipeline time: X:XX:XX
   â€¢ Average processing rate: XX.X docs/second

â±ï¸ PHASE BREAKDOWN:
   â€¢ Initialization: X.XXs (X.X%)
   â€¢ Extraction: X:XX:XX (XX.X%)
   â€¢ Ingestion: X:XX:XX (XX.X%)

ğŸ¯ NEXT STEPS:
   1. Run queries using: uv run python lightrag_query_demo.py
   2. Test simple queries using: uv run python test_simple.py
   3. Database ready for complex medical table relationship queries
======================================================================
```

## After Ingestion is Complete

Once you see "ğŸ‰ PIPELINE COMPLETED SUCCESSFULLY!", the database is ready for complex queries about:

- Table relationships and foreign keys
- Appointment scheduling workflows  
- Clinical encounter connections
- CPT codes and billing relationships
- Medical data flow between tables

## Troubleshooting

- **Rate Limiting**: The script includes automatic delays and retry logic
- **Memory Issues**: Uses batch processing to handle large dataset efficiently
- **API Errors**: Individual document retry for failed batches
- **Progress Tracking**: Real-time updates with ETA calculations

Run the command above to start the full ingestion process.